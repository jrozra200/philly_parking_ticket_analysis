---
title: "Philly Parking Tickets"
author: "Jacob Rozran"
date: "February 25, 2016"
output: html_document
---

# INTRODUCTION

I few weeks ago, I stumblied across [Dylan Purcell's](https://twitter.com/dylancpurcell) 
article on [Philadelphia Parking Violations](http://data.philly.com/philly/parking/). This
 is a nice glimpse of the data, but I wanted to get a taste of it myself. I went and 
 downloaded the entire data set of  [Parking Violations in Philadelphia](https://www.opendataphilly.org/dataset/parking-violations) 
 from the [OpenDataPhilly website](http://opendataphilly.org) and came up with a few 
 questions after checking out the data: 

* How many tickets in the data set?
* What is the range of dates in the data?
* Are there missing days/data?
* What was the biggest/smallest individual fine? What were those fines for? 
Who issued those fines?
* What was the average individual fine amount?
* What day had the most/least count of fines? What is the average amount per day?
* How much $ in fines did they write each day?
* What hour of the day are the most fines issued?
* What day of the week are the most fines issued?
* What day of the month are the most fines issued?
* What state has been issued the most fines?
* Who (what individual) has been issued the most fines?
* How much does the individual with the most fines owe the city?
* How many people have been issued fines?
* What fines are issued the most/least?

And finally to the cool stuff:

* Where were the most fines? Can I see them on a heat map?
* Can I predict the amount of parking tickets by weather data and other factors using linear regression? How about using Random Forests?

With the data and a mission, I got on my way... 

First things first - we need to load the required packages and read in the data. 

```{r load_packages_read_data, include=FALSE}
library(plyr)           # NEEDED TO DO SOME COOL DATA MANIPULATIONS
library(ggplot2)        # LETS ME PLOT THE TICKETS
library(ggmap, quietly = TRUE)  # LETS ME GRAB A MAP OF PHILLY TO PLOT THE TICKETS AGAINST
library(randomForest, quietly = TRUE)   # RANDOM FORESTS = PREDICTIONS... YES!

ptix <- read.csv("Parking_Violations.csv")      ## DATA FILE FROM OPENDATAPHILLY
```

# GENERAL INFO ON THE DATA!

## How many tickets are in the dataset? 

There are **`r dim(ptix)[1]`** tickets in the dataset. That's a good amount!

## What is the range of dates in the data?

For this, we'll have to do some transformations to the data. We convert the time into 
a POSIXct object.

```{r date_transform}
## CONVERT TO A DATETIME OBJECT
ptix$Issue.Date.and.Time <- as.POSIXct(strptime(as.character(ptix$Issue.Date.and.Time), 
                                                format = "%m/%d/%Y %I:%M:%S %p"))
```

And then we can do the calculations on the date range.

```{r date_range}
earliest <- min(ptix$Issue.Date.and.Time)       ## EARLIEST = MINIMUM DATETIME
latest <- max(ptix$Issue.Date.and.Time)         ## LATEST = MAXIMUM DATETIME
range <- latest - earliest                      ## RANGE IS THE DIFFERENCE

print(range)                                    ## PRINT THE RESULTS
```

**`r as.integer(round(range,0))` days!** That ain't half bad! Now - from that range - 
do we have any days missing?

## Are there missing days/data?

Here I convert the datetime variable into a date. I then do a count of tickets per date. 

```{r missing_days}
## CONVERT THE DATETIME TO BE A DATE ONLY
days <- as.data.frame(as.Date(ptix$Issue.Date.and.Time, format = "%m/%d/%Y"))
names(days) <- "date"                   ## NAME THE COLUMN TO SOMETHING NICE
## COUNT THE DATA BY DATE - HOW MANY TICKETS DO WE HAVE EVERY DAY
count_by_day <- ddply(days, .(date), summarize, count = length(date))
```

Here we have data for `r dim(count_by_day)[1]` dates. That is one more than the 
range given above... this may be that we have some overlap that the range 
above misses as it is a more precise calculation. At this point, I am ok with 
saying we don't have any missing days of data (or any surprise extra days of data). 

## General comments on the data

After looking at a summary of the data (I've chosen not to display the summary, 
so you'll have to trust me... there is a lot and it ain't pretty to print)... 
For one, we have a TON of NAs in the Division data. That's fine... 
I don't plan to use that data for anything. The **Standardized Location** and 
**Coordinates** appear to be identical. In that data, there is 
`r length(ptix$Coordinates[ptix$Coordinates == ""])` missing 
events. I think that is ok... that only is only 
`r round(length(ptix$Coordinates[ptix$Coordinates == ""])/length(ptix$Coordinates)*100, 2)`% 
of the data. We could probably back-fill this data looking at the **location** 
field, but the amount shouldn't affect the overall quality of the insights I'm 
gleaning from the data. 

Depending on how I dive into the Violation Descriptions - there seems to be 
multiple varieties of the same violation (some tickets are appended with the 
"CC"). I'll probably want to combine those before doing any analysis on that field.

We now have a good idea of what the data looks like. It is pretty good in size 
and we dont seem to have any missing days of data. At this point, we are ready 
to gain some insight from the data.

# DEEPER INSIGHTS FROM THE DATA

## What was the biggest/smallest individual fine? 

The Fine data is a string and it includes a pesky '$' at the beginning. First we 
have to clean that up and convert the data to a numeric.

```{r cleaning_fine_data}
ptix$Fine <- gsub("\\$", "", ptix$Fine)         ## REMOVE THE '$'
ptix$Fine <- as.numeric(ptix$Fine)              ## CHANGE IT TO A NUMERIC
```

Now the largest and smallest fines:

```{r max_min_fines}
## GRAB THE IMPORTANT COLUMNS FOR WHEN THE FINE IS THE MAXIMUM
maxfine <- ptix[ptix$Fine == max(ptix$Fine), c(1, 5, 7, 8, 9, 10)]
## GRAB THE IMPORTANT COLUMNS FOR WHEN THE FINE IS THE MINIMUM
minfine <- ptix[ptix$Fine == min(ptix$Fine), c(1, 5, 7, 8, 9, 10)]
head(maxfine)   ## SHOW A SNIPPET OF THE MAXFINE DATA
head(minfine)   ## SHOW A SNIPPET OF THE MINFINE DATA
```

Interesting - the same fine `r maxfine$Violation.Description[1]` has the most 
and least expensive fines at the same time. **Executive decision:** the fine should 
really be $`r maxfine$Fine[1]` for all of these. With that, the new minimum fine
is:

```{r fix_min_fines}
ptix$Fine[ptix$Fine == min(ptix$Fine)] <- 2000  ## CHANGING THE $1 FINES TO $2000
## GRAB THE IMPORTANT COLUMNS FOR WHEN THE FINE IS THE MINIMUM NOW
minfine <- ptix[ptix$Fine == min(ptix$Fine), c(1, 5, 7, 8, 9, 10)]
head(minfine)   ## SHOW A SNIPPET OF THE RESULTS
```

And the average fine was $`r round(mean(ptix$Fine), 2)`. It is certainly not 
cheap to get a ticket in Philadelphia. 

## What day had the most/least count of fines? What is the average amount per day?

```{r max_min_day_count}
## DAY WITH THE MOST FINES ISSUED
maxday <- count_by_day[count_by_day$count == max(count_by_day$count), ]
## DAY WITH THE LEAST FINES ISSUED
minday <- count_by_day[count_by_day$count == min(count_by_day$count), ]
avday <- mean(count_by_day$count)       ## CALCULATE THE MEAN
```

On the "best" day (for Philadelphia tax revenue), `r maxday$date`, there were 
`r maxday$count` tickets issued. Contrast that to the "worst" day, 
`r minday$date`, when there were `r maxday$count` tickets issued. On average, 
there are `r avday` parking violations given in Philadelphia per day.

## How much $ in fines did they write each day? Average?

```{r max_min_day_dols}
ptix <- cbind(ptix, days)       ## ADD THE FORMATTED DAYS FIELD TO THE DATA FRAME
## SUMMARIZE THE SUM OF FINES PER DAY
dollars_per_day <- ddply(ptix, .(date), summarize, dols = sum(Fine))
## DAY WITH THE MOST DOLLARS OF FINES ISSUED
maxdols <- dollars_per_day[dollars_per_day$dols == max(dollars_per_day$dols), ]
## DAY WITH THE LEAST DOLLARS OF FINES ISSUED
mindols <- dollars_per_day[dollars_per_day$dols == min(dollars_per_day$dols), ]
## THE AVERAGE AMOUNT IN FINES ISSUED IN A DAY
avgdols <- mean(dollars_per_day$dols)
```

The day with the highest amount, `r maxdols$date`, saw $`r maxdols$dols` in fines 
issued. The lowest amount of fines, $`r mindols$dols`, was issued on 
`r mindols$date`.
